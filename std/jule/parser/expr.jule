// Copyright 2023 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use std::jule::ast::{
	IdentExpr,
	TupleExpr,
	ExprData,
	LitExpr,
	TypeDecl,
	UnaryExpr,
	SubIdentExpr,
	NsSelectionExpr,
	VariadicExpr,
	CastExpr,
	Expr,
	FnCallExpr,
	UnsafeExpr,
	FnDecl,
	FieldExprPair,
	StructLit,
	KeyValPair,
	BraceLit,
	SliceExpr,
	IndexingExpr,
	SlicingExpr,
	BinopExpr,
}
use std::jule::lex::{
	Token,
	TokenId,
	TokenKind,
	range_last,
	is_unary_op,
	range,
	parts,
}

// Returns function expressions without call expression
// if tokens are function call, nil if not.
fn is_fn_call(mut tokens: []Token): []Token {
	match tokens[0].id {
	| TokenId.Range
	| TokenId.Ident
	| TokenId.Prim:
		// Ignore.

	|:
		let tok = tokens[tokens.len-1]
		if tok.id != TokenId.Range && tok.kind != (str)(TokenKind.RParent) {
			ret nil
		}
	}
	let tok = tokens[tokens.len-1]
	if tok.id != TokenId.Range || tok.kind != (str)(TokenKind.RParent) {
		ret nil
	}
	let mut brace_n = 0
	// Loops i >= 1 because expression must be has function expression at begin.
	// For this reason, ignore first token.
	let mut i = tokens.len - 1
	for i >= 1; i-- {
		let tok = tokens[i]
		if tok.id == TokenId.Range {
			match tok.kind {
			| (str)(TokenKind.RParent): brace_n++
			| (str)(TokenKind.LParent): brace_n--
			}
			if brace_n == 0 {
				ret tokens[:i]
			}
		}
	}
	ret nil
}

struct CallData {
	expr_tokens:     []Token
	args_tokens:     []Token
	generics_tokens: []Token
}

fn get_call_data(mut tokens: []Token): &CallData {
	let mut data = &CallData{}
	data.expr_tokens, data.args_tokens = range_last(tokens)
	if data.expr_tokens.len == 0 {
		ret data
	}

	// Below is call expression
	let token = data.expr_tokens[data.expr_tokens.len-1]
	if token.id == TokenId.Range && token.kind == (str)(TokenKind.RBracket) {
		data.expr_tokens, data.generics_tokens = range_last(data.expr_tokens)
	}
	ret data
}

// Returns expression tokens comes before block if exist, nil if not.
fn get_block_expr(mut tokens: []Token): []Token {
	let mut brace_n = 0
	for i, tok in tokens {
		if tok.id == TokenId.Range {
			match tok.kind {
			| (str)(TokenKind.LBrace):
				if brace_n > 0 {
					brace_n++
					break
				}
				ret tokens[:i]

			| (str)(TokenKind.LBracket)
			| (str)(TokenKind.LParent):
				brace_n++

			|:
				brace_n--
			}
		}
	}
	ret nil
}

// Returns colon index, left range and right range tokens.
// Returns nil slice and -1 if not found.
fn split_colon(mut tokens: []Token): ([]Token, []Token) {
	let mut range_n = 0
	for i, token in tokens {
		match token.id {
		| TokenId.Range:
			match token.kind {
			| (str)(TokenKind.LBrace)
			| (str)(TokenKind.LBracket)
			| (str)(TokenKind.LParent):
				range_n++
				continue

			|:
				range_n--
			}
		
		| TokenId.Colon:
			if range_n < 1 {
				let mut l = tokens[:i]
				let mut r = tokens[i+1:]
				ret l, r
			}
		}
	}
	ret nil, nil
}

struct Precedencer {
	pairs: [][]any
}

impl Precedencer {
	fn set(mut self, level: int, expr: any) {
		for i, pair in self.pairs {
			let pair_level = (int)(pair[0])
			if level > pair_level {
				let mut first = self.pairs[:i]
				let mut buffer: [][]any = [[level, expr]]
				let mut appended = append(buffer, self.pairs[i:]...)
				self.pairs = append(first, appended...)
				ret
			}
		}
		self.pairs = append(self.pairs, [level, expr])
	}

	fn get_lower(mut self): any {
		let mut i = self.pairs.len - 1
		for i >= 0; i-- {
			let mut data = self.pairs[i][1]
			if data != nil {
				ret data
			}
		}
		ret nil
	}
}

fn eliminate_comments(mut tokens: []Token): []Token {
	let mut cutted: []Token = nil
	for (_, mut token) in tokens {
		if token.id != TokenId.Comment {
			cutted = append(cutted, token)
		}
	}
	ret cutted
}

// Finds index of priority operator and returns index of operator
// if found, returns -1 if not.
fn find_lowest_prec_op(tokens: []Token): int {
	let mut prec = Precedencer{}
	let mut brace_n = 0
	for i, token in tokens {
		match {
		| token.id == TokenId.Range:
			match token.kind {
			| (str)(TokenKind.LBrace)
			| (str)(TokenKind.LParent)
			| (str)(TokenKind.LBracket):
				brace_n++

			|:
				brace_n--
			}
			continue

		| i == 0:
			continue

		| token.id != TokenId.Op:
			continue

		| brace_n > 0:
			continue
		}

		let left = tokens[i-1]

		// Skip unary operator or type annotation.
		if left.id == TokenId.Op || left.id == TokenId.Colon {
			continue
		}

		if i > 1 && left.id == TokenId.Range && left.kind == (str)(TokenKind.RBracket) {
			let lleft = tokens[i-2]
			if lleft.id == TokenId.Range && lleft.kind == (str)(TokenKind.LBracket) {
				// Skip potential type statements.
				if token.kind == (str)(TokenKind.Amper) || token.kind == (str)(TokenKind.Star) {
					continue
				}
			}
		}

		let p = token.prec()
		if p != -1 {
			prec.set(p, i)
		}
	}

	let data = prec.get_lower()
	if data == nil {
		ret -1
	}
	ret (int)(data)
}

fn build_ident_expr(mut token: Token): &IdentExpr {
	ret &IdentExpr{
		token:      token,
		ident:      token.kind,
		cpp_linked: false,
	}
}

fn get_range_expr_tokens(mut tokens: []Token): ([]Token, int) {
	let mut range_n = 0
	let mut i = tokens.len - 1
	for i >= 0; i-- {
		let tok = tokens[i]
		if tok.id == TokenId.Range {
			match tok.kind {
			| (str)(TokenKind.RBrace)
			| (str)(TokenKind.RBracket)
			| (str)(TokenKind.RParent):
				range_n++
	
			|:
				range_n--
			}
		}

		if range_n == 0 {
			ret tokens[:i], range_n
		}
	}
	ret nil, range_n
}

struct ExprBuilder {
	p: &Parser
}

impl ExprBuilder {
	fn push_err(mut self, token: Token, key: str, args: ...any) {
		self.p.push_err(token, key, args...)
	}

	fn build_tuple(mut self, mut parts: [][]Token): &TupleExpr {
		let mut tuple = &TupleExpr{
			expr: make([]ExprData, parts.len),
		}
		for (i, mut part) in parts {
			tuple.expr[i] = self.build(part)
		}
		ret tuple
	}

	fn build_lit(self, mut token: Token): &LitExpr {
		ret &LitExpr{
			token: token,
			value: token.kind,
		}
	}

	fn build_primitive_type(self, mut token: Token): &TypeDecl {
		ret build_prim_type(token)
	}

	fn build_single(mut self, mut token: Token): ExprData {
		match token.id {
		| TokenId.Lit:
			ret self.build_lit(token)

		| TokenId.Ident
		| TokenId.Self:
			ret build_ident_expr(token)

		| TokenId.Prim:
			ret self.build_primitive_type(token)

		|:
			self.push_err(token, "invalid_syntax")
			ret nil
		}
	}

	fn build_cpp_linked_ident(mut self, mut tokens: []Token): &IdentExpr {
		if tokens[0].id != TokenId.Cpp {
			ret new(IdentExpr)
		} else if tokens[1].id != TokenId.Dot {
			self.push_err(tokens[1], "invalid_syntax")
			ret new(IdentExpr)
		}
		let mut token = tokens[2]
		if token.id != TokenId.Ident {
			self.push_err(tokens[2], "invalid_syntax")
			ret new(IdentExpr)
		}
		let mut expr = build_ident_expr(token)
		expr.cpp_linked = true
		ret expr
	}

	fn build_unary(mut self, mut tokens: []Token): &UnaryExpr {
		let mut op = tokens[0]
		if tokens.len == 1 {
			self.push_err(op, "missing_expr_for_unary")
			ret new(UnaryExpr)
		} else if !is_unary_op(op.kind) {
			self.push_err(op, "invalid_op_for_unary", op.kind)
			ret new(UnaryExpr)
		}

		// Length is 1 cause all length of operator tokens is 1.
		// Change "1" with length of token's value
		// if all operators length is not 1.
		tokens = tokens[1:]

		ret &UnaryExpr{
			op:   op,
			expr: self.build(tokens),
		}
	}

	fn build_obj_sub_ident(mut self, mut tokens: []Token): &SubIdentExpr {
		let mut i = tokens.len - 1
		let mut ident_token = tokens[i]
		i-- // Set offset to delimiter token.
		tokens = tokens[:i] // Remove dot token and selected identifier token.
		if tokens.len == 0 {
			self.push_err(ident_token, "invalid_syntax")
			ret new(SubIdentExpr)
		}
		ret &SubIdentExpr{
			ident: ident_token,
			expr:  self.build(tokens),
		}
	}

	fn build_ns_sub_ident(mut self, mut tokens: []Token): &NsSelectionExpr {
		let mut ns = &NsSelectionExpr{}
		for (i, mut token) in tokens {
			if i%2 == 0 {
				if token.id != TokenId.Ident {
					self.push_err(token, "invalid_syntax")
				}
				ns.ns = append(ns.ns, token)
			} else if token.id != TokenId.DblColon {
				self.push_err(token, "invalid_syntax")
			}
		}
		ns.ident = ns.ns[ns.ns.len-1]
		ns.ns = ns.ns[:ns.ns.len-1]
		ret ns
	}

	fn build_type(mut self, mut tokens: []Token): &TypeDecl {
		let mut i = new(int, 0)
		let (mut t, ok) = self.p.build_type(tokens, i, false)
		if !ok {
			self.push_err(tokens[0], "invalid_syntax")
			ret new(TypeDecl)
		}

		if i < tokens.len {
			self.push_err(tokens[i], "invalid_syntax")
		}
		ret t
	}

	fn build_sub_ident(mut self, mut tokens: []Token): ExprData {
		let i = tokens.len - 2 // Set offset to delimiter token.
		let token = tokens[i]
		match token.id {
		| TokenId.Dot:
			ret self.build_obj_sub_ident(tokens)

		| TokenId.DblColon:
			ret self.build_ns_sub_ident(tokens)

		| TokenId.Range:
			// Catch slice, and array types.
			if token.kind == (str)(TokenKind.RBracket) {
				ret self.build_type(tokens)
			}
		}

		self.push_err(token, "invalid_syntax")
		ret nil
	}

	fn build_variadic(mut self, mut tokens: []Token): &VariadicExpr {
		let mut token = tokens[tokens.len-1] // Variadic operator token.
		tokens = tokens[:tokens.len-1] // Remove variadic operator token.
		ret &VariadicExpr{
			token: token,
			expr:  self.build(tokens),
		}
	}

	fn build_op_right(mut self, mut tokens: []Token): ExprData {
		let mut token = tokens[tokens.len-1]
		match token.kind {
		| (str)(TokenKind.TripleDot):
			ret self.build_variadic(tokens)

		|:
			self.push_err(token, "invalid_syntax")
			ret nil
		}
	}

	fn build_between_parentheses(mut self, mut tokens: []Token): ExprData {
		let token = tokens[0]
		tokens = tokens[1 : tokens.len-1] // Remove parentheses.
		if tokens.len == 0 {
			self.push_err(token, "missing_expr")
			ret nil
		}
		ret self.build(tokens)
	}

	fn try_build_cast(mut self, mut tokens: []Token): &CastExpr {
		let mut range_n = 0
		let error_token = tokens[0]
		for i, token in tokens {
			if token.id == TokenId.Range {
				match token.kind {
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket)
				| (str)(TokenKind.LParent):
					range_n++
					continue

				|:
					range_n--
				}
			}

			if range_n > 0 {
				continue
			} else if i+1 == tokens.len {
				ret new(CastExpr)
			}

			let mut type_tokens = tokens[1:i]
			let mut expr_tokens = tokens[i+1:]

			if expr_tokens.len == 0 {
				// Expression is parentheses group.
				ret new(CastExpr)
			}

			let token = expr_tokens[0]
			if token.id != TokenId.Range || token.kind != (str)(TokenKind.LParent) {
				ret new(CastExpr)
			}

			let mut cast = &CastExpr{}

			// Expression tokens just parentheses.
			if expr_tokens.len == 2 {
				self.push_err(error_token, "missing_expr")
			}

			let mut type_index = new(int, 0)
			let (mut t, ok) = self.p.build_type(type_tokens, type_index, true)
			if ok && type_index < type_tokens.len {
				self.push_err(type_tokens[type_index], "invalid_syntax")
			} else if !ok {
				ret cast
			}
			cast.kind = t

			let mut i = new(int, 0)
			_ = range(i, TokenKind.LParent, TokenKind.RParent, expr_tokens)
			if i < expr_tokens.len {
				ret new(CastExpr)
			}

			cast.expr = self.build(expr_tokens[:i])
			ret cast
		}

		ret new(CastExpr)
	}

	unsafe fn push_arg(mut self, mut args: *[]&Expr, mut tokens: []Token, err_token: Token) {
		if tokens.len == 0 {
			self.push_err(err_token, "invalid_syntax")
			ret
		}
		*args = append(*args, self.build_from_tokens(tokens))
	}

	fn build_args(mut self, mut tokens: []Token): []&Expr {
		// No argument.
		if tokens.len < 2 {
			ret nil
		}

		let mut args: []&Expr = nil
		let mut last = 0
		let mut range_n = 0
		tokens = tokens[1 : tokens.len-1] // Remove parentheses.
		for i, token in tokens {
			if token.id == TokenId.Range {
				match token.kind {
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket)
				| (str)(TokenKind.LParent):
					range_n++

				|:
					range_n--
				}
			}
			if range_n > 0 || token.id != TokenId.Comma {
				continue
			}
			unsafe { self.push_arg(&args, tokens[last:i], token) }
			last = i + 1
		}

		if last < tokens.len {
			if last == 0 {
				if tokens.len > 0 {
					unsafe { self.push_arg(&args, tokens[last:], tokens[last]) }
				}
			} else {
				unsafe { self.push_arg(&args, tokens[last:], tokens[last-1]) }
			}
		}

		ret args
	}

	// Tokens should include brackets.
	fn build_call_generics(mut self, mut tokens: []Token): []&TypeDecl {
		if tokens.len == 0 {
			ret nil
		}

		tokens = tokens[1 : tokens.len-1] // Remove brackets.
		let (mut parts, errs) = parts(tokens, TokenId.Comma, true)
		let mut generics = make([]&TypeDecl, parts.len)
		self.p.errors = append(self.p.errors, errs...)
		for (i, mut part) in parts {
			if part.len == 0 {
				continue
			}
			let mut j = new(int, 0)
			let (mut generic, _) = self.p.build_type(part, j, true)
			if j < part.len {
				self.push_err(part[j], "invalid_syntax")
			}
			generics[i] = generic
		}

		ret generics
	}

	fn build_fn_call(mut self, mut token: Token, mut data: &CallData): &FnCallExpr {
		ret &FnCallExpr{
			token:    token,
			expr:     self.build_from_tokens(data.expr_tokens),
			generics: self.build_call_generics(data.generics_tokens),
			args:     self.build_args(data.args_tokens),
		}
	}

	fn build_parentheses_range(mut self, mut tokens: []Token): ExprData {
		let mut token = tokens[0]
		match token.id {
		| TokenId.Range:
			match token.kind {
			| (str)(TokenKind.LParent):
				let mut expr = self.try_build_cast(tokens)
				if real(expr) {
					ret expr
				}
			}
		}

		let mut data = get_call_data(tokens)

		// Expression is parentheses group if data.expr_tokens is zero.
		// data.args_tokens holds tokens of parentheses range (include parentheses).
		if data.expr_tokens.len == 0 {
			ret self.build_between_parentheses(data.args_tokens)
		}

		ret self.build_fn_call(token, data)
	}

	fn build_unsafe_expr(mut self, mut tokens: []Token): &UnsafeExpr {
		let mut token = tokens[0]
		tokens = tokens[1:] // Remove unsafe keyword.
		let mut i = new(int, 0)
		let mut range_tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if range_tokens.len == 0 {
			self.push_err(tokens[0], "missing_expr")
			ret new(UnsafeExpr)
		}
		ret &UnsafeExpr{
			token: token,
			expr:  self.build_from_tokens(range_tokens).kind,
		}
	}

	fn build_anon_fn(mut self, mut tokens: []Token): &FnDecl {
		ret self.p.build_fn(tokens, false, true, false)
	}

	fn build_unsafe(mut self, mut tokens: []Token): ExprData {
		if tokens.len == 0 {
			self.push_err(tokens[0], "invalid_syntax")
			ret nil
		}

		match tokens[1].id {
		| TokenId.Fn:
			// Unsafe anonymous function.
			ret self.build_anon_fn(tokens)

		|:
			ret self.build_unsafe_expr(tokens)
		}
	}

	// Tokens should include brace tokens.
	fn get_brace_range_lit_expr_parts(mut self, mut tokens: []Token): [][]Token {
		// No part.
		if tokens.len < 2 {
			ret nil
		}

		let mut parts: [][]Token = nil

		let push = fn(mut part: []Token, error_token: Token) {
			if part.len == 0 {
				self.push_err(error_token, "invalid_syntax")
				ret
			}
			parts = append(parts, part)
		}

		let mut last = 0
		let mut range_n = 0
		tokens = tokens[1 : tokens.len-1] // Remove parentheses.
		for i, token in tokens {
			if token.id == TokenId.Range {
				match token.kind {
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket)
				| (str)(TokenKind.LParent):
					range_n++

				|:
					range_n--
				}
			}
			if range_n > 0 || token.id != TokenId.Comma {
				continue
			}
			push(tokens[last:i], token)
			last = i + 1
		}

		if last < tokens.len {
			if last == 0 {
				if tokens.len > 0 {
					push(tokens[last:], tokens[last])
				}
			} else {
				push(tokens[last:], tokens[last-1])
			}
		}

		ret parts
	}

	fn build_field_expr_pair(mut self, mut tokens: []Token): &FieldExprPair {
		let mut pair = &FieldExprPair{
			field: tokens[0],
		}
		tokens = tokens[2:] // Remove field identifier and colon tokens.
		pair.expr = self.build_from_tokens(tokens).kind
		ret pair
	}

	fn build_struct_lit_expr(mut self, mut tokens: []Token): ExprData {
		let token = tokens[0]
		if token.id == TokenId.Ident {
			if tokens.len > 1 {
				let token = tokens[1]
				if token.id == TokenId.Colon {
					ret self.build_field_expr_pair(tokens)
				}
			}
		}
		ret self.build_from_tokens(tokens)
	}

	fn build_struct_lit_exprs(mut self, mut tokens: []Token): []ExprData {
		let mut parts = self.get_brace_range_lit_expr_parts(tokens)
		if parts.len == 0 {
			ret nil
		}

		let mut pairs = make([]ExprData, parts.len)
		for (i, mut part) in parts {
			pairs[i] = self.build_struct_lit_expr(part)
		}
		ret pairs
	}

	fn build_typed_struct_literal(mut self, mut tokens: []Token): &StructLit {
		let mut i = new(int, 0)
		let (mut t, ok) = self.p.build_type(tokens, i, true)
		if !ok {
			ret new(StructLit)
		} else if i >= tokens.len {
			self.push_err(tokens[0], "invalid_syntax")
			ret new(StructLit)
		}

		tokens = tokens[i:] // Remove type tokens.
		let token = tokens[0]
		if token.id != TokenId.Range || token.kind != (str)(TokenKind.LBrace) {
			self.push_err(token, "invalid_syntax")
			ret new(StructLit)
		}

		ret &StructLit{
			kind:  t,
			exprs: self.build_struct_lit_exprs(tokens),
		}
	}

	fn build_brace_lit_part(mut self, mut tokens: []Token): ExprData {
		let (mut l, mut r) = split_colon(tokens)
		// If left is not nil, colon token found.
		if l != nil {
			ret &KeyValPair{
				colon: tokens[l.len],
				key:   self.build_from_tokens(l).kind,
				val:   self.build_from_tokens(r).kind,
			}
		}
		ret self.build_from_tokens(tokens)
	}

	fn build_brace_lit(mut self, mut tokens: []Token): &BraceLit {
		let mut lit = &BraceLit{
			token: tokens[0],
		}

		let mut parts = self.get_brace_range_lit_expr_parts(tokens)
		if parts == nil {
			ret lit
		}

		lit.exprs = make([]ExprData, parts.len)
		for (i, mut part) in parts {
			lit.exprs[i] = self.build_brace_lit_part(part)
		}

		ret lit
	}

	fn build_brace_range(mut self, mut tokens: []Token): ExprData {
		let (expr_tokens, range_n) = get_range_expr_tokens(tokens)

		match {
		| expr_tokens.len == 0:
			ret self.build_brace_lit(tokens)

		| range_n > 0:
			self.push_err(tokens[0], "invalid_syntax")
			ret nil
		}

		match expr_tokens[0].id {
		| TokenId.Unsafe:
			ret self.build_unsafe(tokens)

		| TokenId.Fn:
			ret self.build_anon_fn(tokens)

		| TokenId.Ident
		| TokenId.Cpp:
			ret self.build_typed_struct_literal(tokens)

		|:
			self.push_err(expr_tokens[0], "invalid_syntax")
			ret nil
		}
	}

	// Tokens is should be store enumerable range tokens.
	fn get_enumerable_parts(mut self, mut tokens: []Token): [][]Token {
		tokens = tokens[1 : tokens.len-1] // Remove range tokens.
		let (mut parts, errors) = parts(tokens, TokenId.Comma, true)
		self.p.errors = append(self.p.errors, errors...)
		ret parts
	}

	fn build_slice(mut self, mut tokens: []Token): &SliceExpr {
		let mut slc = &SliceExpr{
			token: tokens[0],
		}

		let mut parts = self.get_enumerable_parts(tokens)
		if parts.len == 0 {
			ret slc
		}

		slc.elems = make([]ExprData, parts.len)
		for (i, mut p) in parts {
			slc.elems[i] = self.build_from_tokens(p).kind
		}

		ret slc
	}

	fn build_indexing(mut self, mut expr_tokens: []Token,
		mut tokens: []Token, mut error_token: Token): &IndexingExpr {
		tokens = tokens[1 : tokens.len-1] // Remove brackets.
		ret &IndexingExpr{
			token: error_token,
			expr:  self.build_from_tokens(expr_tokens).kind,
			index: self.build_from_tokens(tokens).kind,
		}
	}

	fn build_slicing(mut self, mut expr_tokens: []Token, mut slicing_tokens: []Token,
		colon: int, error_token: Token): &SlicingExpr {
		let mut slc = &SlicingExpr{
			token: error_token,
			expr:  self.build_from_tokens(expr_tokens).kind,
		}

		let mut start_expr_tokens = slicing_tokens[:colon]
		if start_expr_tokens.len > 0 {
			slc.start = self.build_from_tokens(start_expr_tokens).kind
		}

		let mut to_expr_tokens = slicing_tokens[colon+1:]
		if to_expr_tokens.len > 0 {
			slc.to = self.build_from_tokens(to_expr_tokens).kind
		}

		ret slc
	}

	fn build_bracket_range(mut self, mut tokens: []Token): ExprData {
		let mut error_token = tokens[0]
		let (mut expr_tokens, range_n) = get_range_expr_tokens(tokens)

		match {
		| expr_tokens.len == 0:
			ret self.build_slice(tokens)

		| expr_tokens.len == 0 || range_n > 0:
			self.push_err(error_token, "invalid_syntax")
			ret nil
		}

		// Remove expression tokens.
		// Holds only indexing tokens.
		// Includes brackets.
		tokens = tokens[expr_tokens.len:]

		// Use split_map_range because same thing.
		// Map types like: [KEY:VALUE]
		// Slicing expressions like: [START:TO]
		let mut i = new(int, 0)
		let (mut slicing_tokens, colon) = split_map_range(tokens, i)
		if colon != -1 {
			ret self.build_slicing(expr_tokens, slicing_tokens, colon, error_token)
		}
		ret self.build_indexing(expr_tokens, tokens, error_token)
	}

	fn build_data(mut self, mut tokens: []Token): ExprData {
		match tokens.len {
		| 0:
			ret nil

		| 1:
			ret self.build_single(tokens[0])

		| 3:
			if tokens[0].id == TokenId.Cpp {
				ret self.build_cpp_linked_ident(tokens)
			}
		}

		let mut token = tokens[0]
		match token.id {
		| TokenId.Op:
			ret self.build_unary(tokens)

		| TokenId.Range:
			if token.kind != (str)(TokenKind.LBracket) || tokens.len < 3 {
				break
			}

			let next = tokens[1]
			if next.id != TokenId.Range || next.kind != (str)(TokenKind.RBracket) {
				break
			}

			ret self.build_type(tokens)
		}

		token = tokens[tokens.len-1]
		match token.id {
		| TokenId.Ident:
			ret self.build_sub_ident(tokens)

		| TokenId.Prim:
			// Catch slice, and array types.
			ret self.build_type(tokens)

		| TokenId.Op:
			ret self.build_op_right(tokens)

		| TokenId.Range:
			match token.kind {
			| (str)(TokenKind.RParent):
				ret self.build_parentheses_range(tokens)

			| (str)(TokenKind.RBrace):
				ret self.build_brace_range(tokens)

			| (str)(TokenKind.RBracket):
				ret self.build_bracket_range(tokens)
			}
		}

		self.push_err(tokens[0], "invalid_syntax")
		ret nil
	}

	fn build_binop(mut self, mut tokens: []Token, i: int): &BinopExpr {
		ret &BinopExpr{
			left:  self.build(tokens[:i]),
			right: self.build(tokens[i+1:]),
			op:    tokens[i],
		}
	}

	fn build(mut self, mut tokens: []Token): ExprData {
		let i = find_lowest_prec_op(tokens)
		if i == -1 {
			ret self.build_data(tokens)
		}
		ret self.build_binop(tokens, i)
	}

	fn build_kind(mut self, mut tokens: []Token): ExprData {
		let (mut parts, errors) = parts(tokens, TokenId.Comma, true)
		if errors != nil {
			self.p.errors = append(self.p.errors, errors...)
			ret nil
		} else if parts.len > 1 {
			ret self.build_tuple(parts)
		}
		ret self.build(tokens)
	}

	fn build_from_tokens(mut self, mut tokens: []Token): &Expr {
		tokens = eliminate_comments(tokens)
		if tokens.len == 0 {
			ret new(Expr)
		}
		ret &Expr{
			token: tokens[0],
			kind:  self.build_kind(tokens),
		}
	}
}
