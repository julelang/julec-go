// Copyright 2023 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use std::jule::ast::{
	ScopeTree,
	NodeData,
	RetSt,
	Iter,
	WhileKind,
	VarDecl,
	RangeKind,
	IterKind,
	BreakSt,
	ContSt,
	If,
	Else,
	Conditional,
	FnCallExpr,
	Expr,
	GotoSt,
	FallSt,
	Case,
	MatchCase,
	LabelSt,
	AssignLeft,
	AssignSt,
}
use std::jule::lex::{
	Token,
	TokenId,
	TokenKind,
	parts,
	range,
	is_assign_op,
	is_postfix_op,
}

fn new_scope(): &ScopeTree {
	ret &ScopeTree{}
}

// Reports whether token is statement finish point.
fn is_st(current: Token, prev: Token): (ok: bool, terminated: bool) {
	ok = current.id == TokenId.Semicolon || prev.row < current.row
	terminated = current.id == TokenId.Semicolon
	ret
}

// Reports position of the next statement if exist, len(toks) if not.
fn next_st_pos(tokens: []Token, start: int): (int, bool) {
	let mut brace_n = 0
	let mut i = start
	for i < tokens.len; i++ {
		let mut ok: bool = false
		let mut terminated: bool = false
		let tok = tokens[i]
		if tok.id == TokenId.Range {
			match tok.kind {
			| (str)(TokenKind.LBrace)
			| (str)(TokenKind.LBracket)
			| (str)(TokenKind.LParent):
				if brace_n == 0 && i > start {
					ok, terminated = is_st(tok, tokens[i-1])
					if ok {
						goto return
					}
				}
				brace_n++
				continue

			|:
				brace_n--
				if brace_n == 0 && i+1 < tokens.len {
					ok, terminated = is_st(tokens[i+1], tok)
					if ok {
						i++
						goto return
					}
				}
				continue
			}
		}

		if brace_n != 0 {
			continue
		} else if i > start {
			ok, terminated = is_st(tok, tokens[i-1])
		} else {
			ok, terminated = is_st(tok, tok)
		}
		if !ok {
			continue
		}

	return:
		if terminated {
			i++
		}
		ret i, terminated
	}
	ret i, false
}

// Returns current statement tokens.
// Starts selection at *i.
unsafe fn skip_st(mut i: *int, mut tokens: []Token): ([]Token, bool) {
	let start = *i
	let mut terminated = false
	*i, terminated = next_st_pos(tokens, start)
	let mut st_tokens = tokens[start:*i]
	if terminated {
		if st_tokens.len == 1 {
			ret skip_st(i, tokens)
		}
		// -1 for eliminate statement terminator.
		st_tokens = st_tokens[:st_tokens.len-1]
	}
	ret st_tokens, terminated
}

struct Stmt {
	tokens:     []Token
	terminated: bool
}

// Splits all statements.
fn split_stms(mut tokens: []Token): []&Stmt {
	let mut stms: []&Stmt = nil
	let mut pos = 0
	for pos < tokens.len {
		let (mut tokens, terminated) = unsafe { skip_st(&pos, tokens) }
		stms = append(stms, &Stmt{
			tokens:     tokens,
			terminated: terminated,
		})
	}
	ret stms
}

struct ScopeParser {
	p:    &Parser
	s:    &ScopeTree
	stms: []&Stmt
	pos:  int
}

impl ScopeParser {
	fn stop(mut self) { self.pos = -1 }
	fn stopped(self): bool { ret self.pos == -1 }
	fn finished(self): bool { ret self.pos >= self.stms.len }
	fn is_last_st(self): bool { ret self.pos+1 >= self.stms.len }
	fn push_err(mut self, token: Token, key: str) { self.p.push_err(token, key) }

	fn insert_as_next(mut self, mut tokens: []Token) {
		self.stms = append(self.stms[:self.pos+1], self.stms[self.pos:]...)
		self.stms[self.pos+1] = &Stmt{tokens: tokens}
	}

	fn next(mut self): &Stmt {
		self.pos++
		ret self.stms[self.pos]
	}

	fn build_scope(mut self, mut tokens: []Token): &ScopeTree {
		let mut s = new_scope()
		s.parent = self.s
		let mut ssp = ScopeParser{
			p: self.p,
		}
		ssp.build(tokens, s)
		ret s
	}

	fn build_var_st(mut self, mut tokens: []Token): NodeData {
		let mut v = self.p.build_var(tokens)
		v.scope = self.s
		ret v
	}

	fn build_ret_st(mut self, mut tokens: []Token): NodeData {
		let mut st = &RetSt{
			token: tokens[0],
		}
		if tokens.len > 1 {
			tokens = tokens[1:] // Remove ret keyword.
			st.expr = self.p.build_expr(tokens)
		}
		ret st
	}

	fn build_while_next_iter(mut self, mut s: &Stmt): NodeData {
		let mut it = &Iter{
			token: s.tokens[0],
		}
		let mut tokens = s.tokens[1:] // Skip "iter" keyword.
		let mut kind = &WhileKind{}

		if tokens.len > 0 {
			kind.expr = self.p.build_expr(tokens)
		}

		if self.is_last_st() {
			self.push_err(it.token, "invalid_syntax")
			ret nil
		}

		tokens = self.next().tokens
		let mut st_tokens = get_block_expr(tokens)
		if st_tokens.len > 0 {
			let mut s = &Stmt{
				terminated: s.terminated,
				tokens:     st_tokens,
			}
			kind.next_token = st_tokens[0]
			kind.next = self.build_st(s)
		}

		let mut i = new(int, st_tokens.len)
		let mut block_tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if block_tokens == nil {
			self.stop()
			self.push_err(it.token, "body_not_exist")
			ret nil
		}
		if i < tokens.len {
			self.push_err(tokens[i], "invalid_syntax")
		}

		it.scope = self.build_scope(block_tokens)
		it.kind = kind

		ret it
	}

	fn build_while_iter_kind(mut self, mut tokens: []Token): &WhileKind {
		ret &WhileKind{
			expr: self.p.build_expr(tokens),
		}
	}

	fn get_range_kind_keys_tokens(mut self, mut toks: []Token): [][]Token {
		let (mut vars, errs) = parts(toks, TokenId.Comma, true)
		self.p.errors = append(self.p.errors, errs...)
		ret vars
	}

	fn build_range_kind_key(mut self, mut tokens: []Token): &VarDecl {
		if tokens.len == 0 {
			ret new(VarDecl)
		}
		let mut key = &VarDecl{
			token: tokens[0],
		}
		if key.token.id == TokenId.Mut {
			key.mutable = true
			if tokens.len == 1 {
				self.push_err(key.token, "invalid_syntax")
			}
			key.token = tokens[1]
		} else if tokens.len > 1 {
			self.push_err(tokens[1], "invalid_syntax")
		}
		if key.token.id != TokenId.Ident {
			self.push_err(key.token, "invalid_syntax")
			ret new(VarDecl)
		}
		key.ident = key.token.kind
		ret key
	}

	fn build_range_kind_keys(mut self, mut parts: [][]Token): []&VarDecl {
		let mut keys: []&VarDecl = nil
		for (_, mut tokens) in parts {
			keys = append(keys, self.build_range_kind_key(tokens))
		}
		ret keys
	}

	fn setup_range_kind_keys_plain(mut self, mut rng: &RangeKind, mut tokens: []Token) {
		let mut key_tokens = self.get_range_kind_keys_tokens(tokens)
		if key_tokens.len == 0 {
			ret
		}
		if key_tokens.len > 2 {
			self.push_err(rng.in_token, "much_range_vars")
		}
		let mut keys = self.build_range_kind_keys(key_tokens)
		rng.key_a = keys[0]
		if keys.len > 1 {
			rng.key_b = keys[1]
		}
	}

	fn setup_range_kind_keys_explicit(mut self, mut rng: &RangeKind, mut tokens: []Token) {
		let mut i = new(int, 0)
		let mut rang = range(i, TokenKind.LParent, TokenKind.RParent, tokens)
		if i < tokens.len {
			self.push_err(rng.in_token, "invalid_syntax")
		}
		self.setup_range_kind_keys_plain(rng, rang)
	}

	fn setup_range_kind_keys(mut self, mut rng: &RangeKind, mut tokens: []Token) {
		if tokens[0].id == TokenId.Range {
			if tokens[0].kind != (str)(TokenKind.LParent) {
				self.push_err(tokens[0], "invalid_syntax")
				ret
			}
			self.setup_range_kind_keys_explicit(rng, tokens)
			ret
		}
		self.setup_range_kind_keys_plain(rng, tokens)
	}

	fn build_range_iter_kind(mut self, mut var_tokens: []Token, mut expr_tokens: []Token, in_token: Token): &RangeKind {
		let mut rng = &RangeKind{
			in_token: in_token,
		}
		if expr_tokens.len == 0 {
			self.push_err(rng.in_token, "missing_expr")
			ret rng
		}
		rng.expr = self.p.build_expr(expr_tokens)
		if var_tokens.len > 0 {
			self.setup_range_kind_keys(rng, var_tokens)
		}
		ret rng
	}

	fn build_common_iter_kind(mut self, mut tokens: []Token, err_tok: Token): IterKind {
		let mut brace_n = 0
		for (i, tok) in tokens {
			if tok.id == TokenId.Range {
				match tok.kind {
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket)
				| (str)(TokenKind.LParent):
					brace_n++
					continue

				|:
					brace_n--
				}
			}
			if brace_n != 0 {
				continue
			}
			match tok.id {
			| TokenId.In:
				let mut decl_tokens = tokens[:i]
				let mut expr_tokens = tokens[i+1:]
				ret self.build_range_iter_kind(decl_tokens, expr_tokens, tok)
			}
		}
		ret self.build_while_iter_kind(tokens)
	}

	fn build_common_iter(mut self, mut tokens: []Token): NodeData {
		let mut it = &Iter{
			token: tokens[0],
		}
		tokens = tokens[1:] // Skip "iter" keyword.
		if tokens.len == 0 {
			self.stop()
			self.push_err(it.token, "body_not_exist")
			ret nil
		}
		let mut expr_tokens = get_block_expr(tokens)
		if expr_tokens.len > 0 {
			it.kind = self.build_common_iter_kind(expr_tokens, it.token)
		}
		let mut i = new(int, expr_tokens.len)
		let mut scope_tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if scope_tokens == nil {
			self.stop()
			self.push_err(it.token, "body_not_exist")
			ret nil
		}
		if i < tokens.len {
			self.push_err(tokens[i], "invalid_syntax")
		}
		it.scope = self.build_scope(scope_tokens)
		ret it
	}

	fn buid_iter_st(mut self, mut st: &Stmt): NodeData {
		if st.terminated {
			ret self.build_while_next_iter(st)
		}
		ret self.build_common_iter(st.tokens)
	}

	fn build_break_st(mut self, mut tokens: []Token): NodeData {
		let mut brk = &BreakSt{
			token: tokens[0],
		}
		if tokens.len > 1 {
			if tokens[1].id != TokenId.Ident {
				self.push_err(tokens[1], "invalid_syntax")
			} else {
				brk.label = tokens[1]
				if tokens.len > 2 {
					self.push_err(tokens[1], "invalid_syntax")
				}
			}
		}
		ret brk
	}

	fn build_cont_st(mut self, mut tokens: []Token): NodeData {
		let mut cont = &ContSt{
			token: tokens[0],
		}
		if tokens.len > 1 {
			if tokens[1].id != TokenId.Ident {
				self.push_err(tokens[1], "invalid_syntax")
			} else {
				cont.label = tokens[1]
				if tokens.len > 2 {
					self.push_err(tokens[1], "invalid_syntax")
				}
			}
		}
		ret cont
	}

	unsafe fn build_if(mut self, mut tokens: *[]Token): &If {
		let mut model = &If{
			token: (*tokens)[0],
		}
		*tokens = (*tokens)[1:]
		let mut expr_tokens = get_block_expr(*tokens)
		let mut i = new(int, 0)
		if expr_tokens.len == 0 {
			self.push_err(model.token, "missing_expr")
		} else {
			i = expr_tokens.len
		}
		let mut scope_tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, *tokens)
		if scope_tokens == nil {
			self.stop()
			self.push_err(model.token, "body_not_exist")
			ret new(If)
		}
		if i < (*tokens).len {
			if (*tokens)[i].id == TokenId.Else {
				*tokens = (*tokens)[i:]
			} else {
				self.push_err((*tokens)[i], "invalid_syntax")
				*tokens = nil
			}
		}
		model.expr = self.p.build_expr(expr_tokens)
		model.scope = self.build_scope(scope_tokens)
		ret model
	}

	fn build_else(mut self, mut tokens: []Token): &Else {
		let mut els = &Else{
			token: tokens[0],
		}
		tokens = tokens[1:] // Remove "else" keyword.
		let mut i = new(int, 0)
		let mut scope_tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if scope_tokens == nil {
			if i < tokens.len {
				self.push_err(els.token, "else_have_expr")
			} else {
				self.stop()
				self.push_err(els.token, "body_not_exist")
			}
			ret new(Else)
		}
		if i < tokens.len {
			self.push_err(tokens[i], "invalid_syntax")
		}
		els.scope = self.build_scope(scope_tokens)
		ret els
	}

	fn build_if_else_chain(mut self, mut tokens: []Token): NodeData {
		let mut chain = &Conditional{
			head: unsafe { self.build_if(&tokens) },
		}
		if !real(chain.head) {
			ret nil
		}
		for tokens != nil {
			if tokens[0].id != TokenId.Else {
				break
			}
			if tokens.len > 1 && tokens[1].id == TokenId.If {
				tokens = tokens[1:] // Remove else token
				let mut elif = unsafe { self.build_if(&tokens) }
				chain.tail = append(chain.tail, elif)
				continue
			}
			chain.default = self.build_else(tokens)
			break
		}
		ret chain
	}

	fn build_comment_st(self, mut token: Token): NodeData {
		ret build_comment(token)
	}

	fn build_call_st(mut self, mut tokens: []Token): NodeData {
		let token = tokens[0]
		if is_fn_call(tokens) == nil {
			self.push_err(token, "expr_not_func_call")
		}
		let mut expr = self.p.build_expr(tokens)
		if real(expr) && !expr.is_fn_call() {
			self.push_err(token, "invalid_syntax")
		}
		ret expr
	}

	fn build_co_call_st(mut self, mut tokens: []Token): NodeData {
		tokens = tokens[1:] // Skip "co" token.
		let mut cc = self.build_call_st(tokens)
		(&FnCallExpr)((&Expr)(cc).kind).concurrent = true
		ret cc
	}

	fn build_goto_st(mut self, mut tokens: []Token): NodeData {
		let mut gt = &GotoSt{
			token: tokens[0],
		}
		if tokens.len == 1 {
			self.push_err(gt.token, "missing_goto_label")
			ret nil
		} else if tokens.len > 2 {
			self.push_err(tokens[2], "invalid_syntax")
		}
		let mut ident_token = tokens[1]
		if ident_token.id != TokenId.Ident {
			self.push_err(ident_token, "invalid_syntax")
			ret gt
		}
		gt.label = ident_token
		ret gt
	}

	fn build_fall_st(mut self, mut tokens: []Token): NodeData {
		let mut fll = &FallSt{
			token: tokens[0],
		}
		if tokens.len > 1 {
			self.push_err(tokens[1], "invalid_syntax")
		}
		ret fll
	}

	fn build_type_alias_st(mut self, mut tokens: []Token): NodeData {
		let mut tad = self.p.build_type_alias_decl(tokens)
		tad.scope = self.s
		ret tad
	}

	unsafe fn build_case_exprs(mut self, mut tokens: *[]Token, type_match: bool): []&Expr {
		let mut exprs: []&Expr = nil
		let push_expr = fn(mut tokens: []Token, mut token: Token) {
			if tokens.len > 0 {
				if type_match {
					let mut i = new(int, 0)
					let (mut t, ok) = self.p.build_type(tokens, i, true)
					if ok {
						exprs = append(exprs, &Expr{
							token: token,
							kind:  t,
						})
					}
					if i < tokens.len {
						self.push_err(tokens[i], "invalid_syntax")
					}
					ret
				}
				exprs = append(exprs, self.p.build_expr(tokens))
			}
		}

		let mut brace_n = 0
		let mut j = 0
		for (i, mut tok) in *tokens {
			if tok.id == TokenId.Range {
				match tok.kind {
				| (str)(TokenKind.LParent)
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket):
					brace_n++

				|:
					brace_n--
				}
				continue
			} else if brace_n != 0 {
				continue
			}
			match {
			| tok.id == TokenId.Op && tok.kind == (str)(TokenKind.Vline):
				push_expr((*tokens)[j:i], tok)
				j = i + 1

			| tok.id == TokenId.Colon:
				push_expr((*tokens)[j:i], tok)
				*tokens = (*tokens)[i+1:]
				ret exprs
			}
		}
		self.push_err((*tokens)[0], "invalid_syntax")
		*tokens = nil
		ret nil
	}

	unsafe fn build_case_scope(mut self, mut tokens: *[]Token): &ScopeTree {
		let mut n = 0
		for {
			let mut i = 0
			let (mut next, _) = skip_st(&i, (*tokens)[n:])
			if next.len == 0 {
				break
			}
			let tok = next[0]
			if tok.id != TokenId.Op || tok.kind != (str)(TokenKind.Vline) {
				n += next.len
				continue
			}
			let mut scope = self.build_scope((*tokens)[:n])
			*tokens = (*tokens)[n:]
			ret scope
		}
		let mut scope = self.build_scope(*tokens)
		*tokens = nil
		ret scope
	}

	unsafe fn build_case(mut self, mut tokens: *[]Token, type_match: bool): (&Case, bool) {
		let mut c = &Case{
			token: (*tokens)[0], 
		}
		*tokens = (*tokens)[1:] // Remove case prefix.
		c.exprs = self.build_case_exprs(tokens, type_match)
		c.scope = self.build_case_scope(tokens)
		let is_default = c.exprs.len == 0
		ret c, is_default
	}

	fn build_cases(mut self, mut tokens: []Token, type_match: bool): ([]&Case, &Else) {
		let mut cases: []&Case = nil
		let mut def: &Else = new(Else)
		for tokens.len > 0 {
			let mut tok = tokens[0]
			if tok.id != TokenId.Op || tok.kind != (str)(TokenKind.Vline) {
				self.push_err(tok, "invalid_syntax")
				break
			}
			let (mut c, is_default) = unsafe { self.build_case(&tokens, type_match) }
			if is_default {
				c.token = tok
				if !real(def) {
					def = &Else{
						token: c.token,
						scope: c.scope,
					}
				} else {
					self.push_err(tok, "invalid_syntax")
				}
			} else {
				cases = append(cases, c)
			}
		}
		ret cases, def
	}

	fn build_match_case(mut self, mut tokens: []Token): &MatchCase {
		let mut m = &MatchCase{
			token: tokens[0],
		}
		tokens = tokens[1:] // Remove "match" keyword.

		if tokens.len > 0 && tokens[0].id == TokenId.Type {
			m.type_match = true
			tokens = tokens[1:] // Skip "type" keyword
		}

		let mut expr_tokens = get_block_expr(tokens)
		if expr_tokens.len > 0 {
			m.expr = self.p.build_expr(expr_tokens)
		} else if m.type_match {
			self.push_err(m.token, "missing_expr")
		}

		let mut i = new(int, expr_tokens.len)
		let mut block_toks = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if block_toks == nil {
			self.stop()
			self.push_err(m.token, "body_not_exist")
			ret new(MatchCase)
		}

		m.cases, m.default = self.build_cases(block_toks, m.type_match)
		ret m
	}

	fn build_scope_st(mut self, mut tokens: []Token): &ScopeTree {
		let mut is_unsafe = false
		let mut is_deferred = false
		let mut token = tokens[0]
		if token.id == TokenId.Unsafe {
			is_unsafe = true
			tokens = tokens[1:]
			if tokens.len == 0 {
				self.push_err(token, "invalid_syntax")
				ret new(ScopeTree)
			}
			token = tokens[0]
			if token.id == TokenId.Defer {
				is_deferred = true
				tokens = tokens[1:]
				if tokens.len == 0 {
					self.push_err(token, "invalid_syntax")
					ret new(ScopeTree)
				}
			}
		} else if token.id == TokenId.Defer {
			is_deferred = true
			tokens = tokens[1:]
			if tokens.len == 0 {
				self.push_err(token, "invalid_syntax")
				ret new(ScopeTree)
			}
		}

		let mut i = new(int, 0)
		tokens = range(i, TokenKind.LBrace, TokenKind.RBrace, tokens)
		if tokens == nil {
			self.push_err(token, "invalid_syntax")
			ret new(ScopeTree)
		} else if i < tokens.len {
			self.push_err(tokens[i], "invalid_syntax")
		}
		let mut scope = self.build_scope(tokens)
		scope.unsafety = is_unsafe
		scope.deferred = is_deferred
		ret scope
	}

	fn build_label_st(mut self, mut tokens: []Token): &LabelSt {
		let mut lbl = &LabelSt{
			token: tokens[0],
			ident: tokens[0].kind,
		}

		// Save followed statement
		if tokens.len > 2 {
			tokens = tokens[2:] // Remove goto keyword and label
			self.insert_as_next(tokens)
		}

		ret lbl
	}

	fn build_id_st(mut self, mut tokens: []Token): (NodeData, ok: bool) {
		if tokens.len == 1 {
			ret
		}

		let mut token = tokens[1]
		match token.id {
		| TokenId.Colon:
			ret self.build_label_st(tokens), true
		}

		ret
	}

	fn build_assign_info(mut self, mut tokens: []Token): &AssignInfo {
		let mut info = &AssignInfo{
			ok: true,
		}
		let mut brace_n = 0
		for (i, mut token) in tokens {
			if token.id == TokenId.Range {
				match token.kind {
				| (str)(TokenKind.LBrace)
				| (str)(TokenKind.LBracket)
				| (str)(TokenKind.LParent):
					brace_n++

				|:
					brace_n--
				}
			}

			match {
			| brace_n > 0:               continue
			| token.id != TokenId.Op:    continue
			| !is_assign_op(token.kind): continue
			}

			info.l = tokens[:i]
			if info.l.len == 0 {
				info.ok = false
			}
			info.setter = token
			if i+1 >= tokens.len {
				info.r = nil
				info.ok = is_postfix_op(info.setter.kind)
				break
			}
			info.r = tokens[i+1:]
			if is_postfix_op(info.setter.kind) {
				if info.r.len > 0 {
					self.push_err(info.r[0], "invalid_syntax")
					info.r = nil
				}
			}

			break
		}
		ret info
	}

	fn build_assign_l(mut self, mut tokens: []Token): &AssignLeft {
		let mut l = &AssignLeft{
			token: tokens[0],
		}

		if tokens[0].id == TokenId.Ident {
			l.ident = l.token.kind
		}

		l.expr = self.p.build_expr(tokens)
		ret l
	}

	fn build_assign_ls(mut self, mut parts: [][]Token): []&AssignLeft {
		let mut lefts: []&AssignLeft = nil
		for (_, mut part) in parts {
			let mut l = self.build_assign_l(part)
			lefts = append(lefts, l)
		}

		ret lefts
	}

	fn build_plain_assign(mut self, mut tokens: []Token): (&AssignSt, bool) {
		let mut info = self.build_assign_info(tokens)
		if !info.ok {
			ret new(AssignSt), false
		}

		let mut assign = &AssignSt{
			setter: info.setter,
		}

		let (mut parts, errs) = parts(info.l, TokenId.Comma, true)
		if errs.len > 0 {
			self.p.errors = append(self.p.errors, errs...)
			ret new(AssignSt), false
		}

		assign.left = self.build_assign_ls(parts)
		if info.r != nil {
			assign.right = self.p.build_expr(info.r)
		}

		ret assign, true
	}

	fn build_decl_assign(mut self, mut tokens: []Token): (&AssignSt, bool) {
		if tokens.len < 1 {
			ret new(AssignSt), false
		}

		tokens = tokens[1:] // Skip "let" keyword
		let token = tokens[0]
		if token.id != TokenId.Range || token.kind != (str)(TokenKind.LParent) {
			ret new(AssignSt), false
		}

		let mut assign = &AssignSt{
			declarative: true,
		}

		let mut i = new(int, 0)
		let mut rang = range(i, TokenKind.LParent, TokenKind.RParent, tokens)
		if rang == nil {
			self.push_err(token, "invalid_syntax")
			ret new(AssignSt), false
		} else if i+1 < tokens.len {
			assign.setter = tokens[i]
			i++
			assign.right = self.p.build_expr(tokens[i:])
		}

		// Lefts
		let (mut parts, errs) = parts(rang, TokenId.Comma, true)
		if errs.len > 0 {
			self.p.errors = append(self.p.errors, errs...)
			ret new(AssignSt), false
		}

		for (_, mut part) in parts {
			let mut is_mut = false
			let token = part[0]
			if token.id == TokenId.Mut {
				is_mut = true
				part = part[1:]
				if part.len != 1 {
					self.push_err(token, "invalid_syntax")
					continue
				}
			}

			if (part[0].id != TokenId.Ident &&
				part[0].id != TokenId.Range &&
				part[0].kind != (str)(TokenKind.LParent)) {
				self.push_err(token, "invalid_syntax")
				continue
			}

			let mut l = self.build_assign_l(part)
			l.mutable = is_mut
			assign.left = append(assign.left, l)
		}

		ret assign, true
	}

	fn build_assign_st(mut self, mut tokens: []Token): (&AssignSt, bool) {
		if !check_assign_tokens(tokens) {
			ret new(AssignSt), false
		}

		match tokens[0].id {
		| TokenId.Let: ret self.build_decl_assign(tokens)
		|:             ret self.build_plain_assign(tokens)
		}
	}

	fn build_st(mut self, mut st: &Stmt): NodeData {
		let mut token = st.tokens[0]
		if token.id == TokenId.Ident {
			let (mut s, ok) = self.build_id_st(st.tokens)
			if ok {
				ret s
			}
		}

		let (mut s, ok) = self.build_assign_st(st.tokens)
		if ok {
			ret s
		}

		match token.id {
		| TokenId.Const
		| TokenId.Let
		| TokenId.Mut:
			ret self.build_var_st(st.tokens)

		| TokenId.Ret:
			ret self.build_ret_st(st.tokens)

		| TokenId.Iter:
			ret self.buid_iter_st(st)

		| TokenId.Break:
			ret self.build_break_st(st.tokens)

		| TokenId.Cont:
			ret self.build_cont_st(st.tokens)

		| TokenId.If:
			ret self.build_if_else_chain(st.tokens)

		| TokenId.Comment:
			// Push first token because this is full text comment.
			// Comments are just single-line.
			// Range comments not accepts by lexer.
			ret self.build_comment_st(token)

		| TokenId.Co:
			ret self.build_co_call_st(st.tokens)

		| TokenId.Goto:
			ret self.build_goto_st(st.tokens)

		| TokenId.Fall:
			ret self.build_fall_st(st.tokens)

		| TokenId.Type:
			ret self.build_type_alias_st(st.tokens)

		| TokenId.Match:
			ret self.build_match_case(st.tokens)

		| TokenId.Unsafe
		| TokenId.Defer:
			ret self.build_scope_st(st.tokens)

		| TokenId.Range:
			if token.kind == (str)(TokenKind.LBrace) {
				ret self.build_scope_st(st.tokens)
			}

		|:
			if is_fn_call(st.tokens) != nil {
				ret self.build_call_st(st.tokens)
			}
		}

		self.push_err(token, "invalid_syntax")
		ret nil
	}

	fn build(mut self, mut tokens: []Token, mut s: &ScopeTree) {
		if !real(s) {
			ret
		}

		self.stms = split_stms(tokens)
		self.pos = -1 // sp.next() first increase position
		self.s = s
		for !self.is_last_st() && !self.finished() {
			let mut st = self.next()
			let mut data = self.build_st(st)
			if data != nil {
				self.s.stmts = append(self.s.stmts, data)
			}

			if self.stopped() {
				break
			}
		}
	}
}
